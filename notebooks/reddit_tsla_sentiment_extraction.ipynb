{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tsla text data from Reddit\n",
    "\n",
    "https://gcdi.commons.gc.cuny.edu/2024/11/01/web-scraping-with-python-and-the-reddit-api/\n",
    "See PRAW documentation: https://praw.readthedocs.io/en/latest/getting_started/configuration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS RESULTS\n",
      "============================================================\n",
      "Total posts analyzed: 526\n",
      "Date range: 2024-06-01 to 2025-07-22\n",
      "Average sentiment score: 0.803\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     346\n",
      "negative     93\n",
      "positive     87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Collection method distribution:\n",
      "collection_method\n",
      "search_elon musk            91\n",
      "search_full self driving    69\n",
      "search_ev                   60\n",
      "search_tesla                56\n",
      "search_tsla                 53\n",
      "search_elon                 42\n",
      "search_electric vehicle     39\n",
      "search_spacex               39\n",
      "search_robotaxi             30\n",
      "search_fsd                  17\n",
      "search_cybertruck           14\n",
      "search_battery day           6\n",
      "search_supercharger          5\n",
      "search_autopilot             3\n",
      "search_neuralink             1\n",
      "search_gigafactory           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Flair distribution:\n",
      "flair\n",
      "Discussion         157\n",
      "News               109\n",
      "DD                 107\n",
      "Gain                80\n",
      "YOLO                49\n",
      "Loss                15\n",
      "Meme                 6\n",
      "Shitpost             2\n",
      "Earnings Thread      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Daily post counts:\n",
      "date\n",
      "2024-06-04    1\n",
      "2024-06-05    1\n",
      "2024-06-07    1\n",
      "2024-06-10    4\n",
      "2024-06-11    1\n",
      "             ..\n",
      "2025-07-15    1\n",
      "2025-07-16    2\n",
      "2025-07-17    4\n",
      "2025-07-18    4\n",
      "2025-07-21    6\n",
      "Name: count, Length: 222, dtype: int64\n",
      "\n",
      "Top 5 posts by Reddit score:\n",
      "                                                 title  reddit_score  \\\n",
      "208  [Fortune] Elon Musk's Tesla reportedly halts C...         24730   \n",
      "359  $80,000 to $1.12M in 7 days. Thank you Elon Mu...         19487   \n",
      "279  Trump says he will declare national energy eme...         17133   \n",
      "63                   Is this spelling that on purpose?         15817   \n",
      "51   I tried to tell my Father, but he was hell ben...         12588   \n",
      "\n",
      "    sentiment  sentiment_score        date       flair  \n",
      "208  negative         0.949766  2025-03-14        News  \n",
      "359   neutral         0.883343  2024-11-11        Gain  \n",
      "279  negative         0.557780  2025-01-21        News  \n",
      "63    neutral         0.900921  2025-06-20  Discussion  \n",
      "51    neutral         0.637736  2025-06-25        Gain  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>collection_method</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1m5yp45</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 18:36:38</td>\n",
       "      <td>Muted Results but Booming Guidance: NVDA Q2 Ea...</td>\n",
       "      <td>Muted Results but Booming Guidance NVDA Q2 Ear...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.89</td>\n",
       "      <td>16</td>\n",
       "      <td>hazxrrd</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.878628</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_full self driving</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1m5nb20</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 11:18:41</td>\n",
       "      <td>If it’s good enough to screenshot it’s good en...</td>\n",
       "      <td>If it s good enough to screenshot it s good en...</td>\n",
       "      <td>535</td>\n",
       "      <td>0.95</td>\n",
       "      <td>55</td>\n",
       "      <td>Phazem</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.503953</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tsla</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1m5lmlv</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 10:15:55</td>\n",
       "      <td>OPEN your eyes</td>\n",
       "      <td>OPEN your eyes Hold the fucking line</td>\n",
       "      <td>231</td>\n",
       "      <td>0.95</td>\n",
       "      <td>14</td>\n",
       "      <td>Delicious-Cress6983</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.857597</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tesla</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1m46wiu</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:59:40</td>\n",
       "      <td>$14k in a day (TSLA Puts)</td>\n",
       "      <td>14k in a day TSLA Puts</td>\n",
       "      <td>67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10</td>\n",
       "      <td>TrueButterfly3908</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tsla</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1m46fuj</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:39:06</td>\n",
       "      <td>Google’s AI Awakening: Earnings Bull Case</td>\n",
       "      <td>Google s AI Awakening Earnings Bull Case Beyon...</td>\n",
       "      <td>300</td>\n",
       "      <td>0.88</td>\n",
       "      <td>150</td>\n",
       "      <td>wanderingtofu</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.687717</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_full self driving</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date             datetime  \\\n",
       "0  1m5yp45  2025-07-21  2025-07-21 18:36:38   \n",
       "1  1m5nb20  2025-07-21  2025-07-21 11:18:41   \n",
       "2  1m5lmlv  2025-07-21  2025-07-21 10:15:55   \n",
       "3  1m46wiu  2025-07-21  2025-07-19 15:59:40   \n",
       "4  1m46fuj  2025-07-21  2025-07-19 15:39:06   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muted Results but Booming Guidance: NVDA Q2 Ea...   \n",
       "1  If it’s good enough to screenshot it’s good en...   \n",
       "2                                     OPEN your eyes   \n",
       "3                          $14k in a day (TSLA Puts)   \n",
       "4          Google’s AI Awakening: Earnings Bull Case   \n",
       "\n",
       "                                                text  reddit_score  \\\n",
       "0  Muted Results but Booming Guidance NVDA Q2 Ear...            57   \n",
       "1  If it s good enough to screenshot it s good en...           535   \n",
       "2               OPEN your eyes Hold the fucking line           231   \n",
       "3                             14k in a day TSLA Puts            67   \n",
       "4  Google s AI Awakening Earnings Bull Case Beyon...           300   \n",
       "\n",
       "   upvote_ratio  num_comments               author sentiment  sentiment_score  \\\n",
       "0          0.89            16              hazxrrd  negative         0.878628   \n",
       "1          0.95            55               Phazem  positive         0.503953   \n",
       "2          0.95            14  Delicious-Cress6983   neutral         0.857597   \n",
       "3          0.86            10    TrueButterfly3908   neutral         0.855079   \n",
       "4          0.88           150        wanderingtofu   neutral         0.687717   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "1  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "2  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "3  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "4  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "\n",
       "          collection_method       flair  \n",
       "0  search_full self driving          DD  \n",
       "1               search_tsla        YOLO  \n",
       "2              search_tesla        YOLO  \n",
       "3               search_tsla        Gain  \n",
       "4  search_full self driving  Discussion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delegate to models/reddit_sentiment.py\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from models.reddit_sentiment import run_reddit_sentiment\n",
    "\n",
    "OUTPUT_CSV = PROJECT_ROOT / 'data' / 'interim' / 'activitiy recognition' / 'tesla_sentiment.csv'\n",
    "\n",
    "START = datetime(2024, 6, 1)\n",
    "END = datetime(2025, 7, 22)\n",
    "\n",
    "result_df = run_reddit_sentiment(\n",
    "    subreddit_name='wallstreetbets',\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    max_posts=2000,\n",
    "    output_csv=str(OUTPUT_CSV),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check Reddit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def connect_to_reddit():\n",
    "#     reddit = praw.Reddit(\n",
    "#         client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "#         client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "#         user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    "#     )\n",
    "#     return reddit\n",
    "\n",
    "# reddit = connect_to_reddit()\n",
    "\n",
    "# # Define the subreddit\n",
    "# subreddit = reddit.subreddit('wallstreetbets')\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# for submission in subreddit.hot(limit=1):\n",
    "#     attrs = dir(submission)\n",
    "#     df = pd.DataFrame(attrs, columns=['attribute'])\n",
    "#     display(df)\n",
    "    \n",
    "# df.to_csv('reddit_class')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
