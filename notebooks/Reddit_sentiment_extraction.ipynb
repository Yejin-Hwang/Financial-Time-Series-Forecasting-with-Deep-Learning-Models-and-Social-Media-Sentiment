{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tsla text data from Reddit\n",
    "\n",
    "https://gcdi.commons.gc.cuny.edu/2024/11/01/web-scraping-with-python-and-the-reddit-api/\n",
    "See PRAW documentation: https://praw.readthedocs.io/en/latest/getting_started/configuration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS RESULTS\n",
      "============================================================\n",
      "Total posts analyzed: 526\n",
      "Date range: 2024-06-01 to 2025-07-22\n",
      "Average sentiment score: 0.803\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     346\n",
      "negative     93\n",
      "positive     87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Collection method distribution:\n",
      "collection_method\n",
      "search_elon musk            91\n",
      "search_full self driving    69\n",
      "search_ev                   60\n",
      "search_tesla                56\n",
      "search_tsla                 53\n",
      "search_elon                 42\n",
      "search_electric vehicle     39\n",
      "search_spacex               39\n",
      "search_robotaxi             30\n",
      "search_fsd                  17\n",
      "search_cybertruck           14\n",
      "search_battery day           6\n",
      "search_supercharger          5\n",
      "search_autopilot             3\n",
      "search_neuralink             1\n",
      "search_gigafactory           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Flair distribution:\n",
      "flair\n",
      "Discussion         157\n",
      "News               109\n",
      "DD                 107\n",
      "Gain                80\n",
      "YOLO                49\n",
      "Loss                15\n",
      "Meme                 6\n",
      "Shitpost             2\n",
      "Earnings Thread      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Daily post counts:\n",
      "date\n",
      "2024-06-04    1\n",
      "2024-06-05    1\n",
      "2024-06-07    1\n",
      "2024-06-10    4\n",
      "2024-06-11    1\n",
      "             ..\n",
      "2025-07-15    1\n",
      "2025-07-16    2\n",
      "2025-07-17    4\n",
      "2025-07-18    4\n",
      "2025-07-21    6\n",
      "Name: count, Length: 222, dtype: int64\n",
      "\n",
      "Top 5 posts by Reddit score:\n",
      "                                                 title  reddit_score  \\\n",
      "208  [Fortune] Elon Musk's Tesla reportedly halts C...         24730   \n",
      "359  $80,000 to $1.12M in 7 days. Thank you Elon Mu...         19487   \n",
      "279  Trump says he will declare national energy eme...         17133   \n",
      "63                   Is this spelling that on purpose?         15817   \n",
      "51   I tried to tell my Father, but he was hell ben...         12588   \n",
      "\n",
      "    sentiment  sentiment_score        date       flair  \n",
      "208  negative         0.949766  2025-03-14        News  \n",
      "359   neutral         0.883343  2024-11-11        Gain  \n",
      "279  negative         0.557780  2025-01-21        News  \n",
      "63    neutral         0.900921  2025-06-20  Discussion  \n",
      "51    neutral         0.637736  2025-06-25        Gain  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>collection_method</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1m5yp45</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 18:36:38</td>\n",
       "      <td>Muted Results but Booming Guidance: NVDA Q2 Ea...</td>\n",
       "      <td>Muted Results but Booming Guidance NVDA Q2 Ear...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.89</td>\n",
       "      <td>16</td>\n",
       "      <td>hazxrrd</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.878628</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_full self driving</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1m5nb20</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 11:18:41</td>\n",
       "      <td>If it’s good enough to screenshot it’s good en...</td>\n",
       "      <td>If it s good enough to screenshot it s good en...</td>\n",
       "      <td>535</td>\n",
       "      <td>0.95</td>\n",
       "      <td>55</td>\n",
       "      <td>Phazem</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.503953</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tsla</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1m5lmlv</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 10:15:55</td>\n",
       "      <td>OPEN your eyes</td>\n",
       "      <td>OPEN your eyes Hold the fucking line</td>\n",
       "      <td>231</td>\n",
       "      <td>0.95</td>\n",
       "      <td>14</td>\n",
       "      <td>Delicious-Cress6983</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.857597</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tesla</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1m46wiu</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:59:40</td>\n",
       "      <td>$14k in a day (TSLA Puts)</td>\n",
       "      <td>14k in a day TSLA Puts</td>\n",
       "      <td>67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10</td>\n",
       "      <td>TrueButterfly3908</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tsla</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1m46fuj</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:39:06</td>\n",
       "      <td>Google’s AI Awakening: Earnings Bull Case</td>\n",
       "      <td>Google s AI Awakening Earnings Bull Case Beyon...</td>\n",
       "      <td>300</td>\n",
       "      <td>0.88</td>\n",
       "      <td>150</td>\n",
       "      <td>wanderingtofu</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.687717</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_full self driving</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date             datetime  \\\n",
       "0  1m5yp45  2025-07-21  2025-07-21 18:36:38   \n",
       "1  1m5nb20  2025-07-21  2025-07-21 11:18:41   \n",
       "2  1m5lmlv  2025-07-21  2025-07-21 10:15:55   \n",
       "3  1m46wiu  2025-07-21  2025-07-19 15:59:40   \n",
       "4  1m46fuj  2025-07-21  2025-07-19 15:39:06   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muted Results but Booming Guidance: NVDA Q2 Ea...   \n",
       "1  If it’s good enough to screenshot it’s good en...   \n",
       "2                                     OPEN your eyes   \n",
       "3                          $14k in a day (TSLA Puts)   \n",
       "4          Google’s AI Awakening: Earnings Bull Case   \n",
       "\n",
       "                                                text  reddit_score  \\\n",
       "0  Muted Results but Booming Guidance NVDA Q2 Ear...            57   \n",
       "1  If it s good enough to screenshot it s good en...           535   \n",
       "2               OPEN your eyes Hold the fucking line           231   \n",
       "3                             14k in a day TSLA Puts            67   \n",
       "4  Google s AI Awakening Earnings Bull Case Beyon...           300   \n",
       "\n",
       "   upvote_ratio  num_comments               author sentiment  sentiment_score  \\\n",
       "0          0.89            16              hazxrrd  negative         0.878628   \n",
       "1          0.95            55               Phazem  positive         0.503953   \n",
       "2          0.95            14  Delicious-Cress6983   neutral         0.857597   \n",
       "3          0.86            10    TrueButterfly3908   neutral         0.855079   \n",
       "4          0.88           150        wanderingtofu   neutral         0.687717   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "1  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "2  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "3  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "4  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "\n",
       "          collection_method       flair  \n",
       "0  search_full self driving          DD  \n",
       "1               search_tsla        YOLO  \n",
       "2              search_tesla        YOLO  \n",
       "3               search_tsla        Gain  \n",
       "4  search_full self driving  Discussion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delegate to models/reddit_sentiment.py\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from models.reddit_tsla_sentiment import run_reddit_tsla_sentiment as run_reddit_sentiment\n",
    "\n",
    "OUTPUT_CSV = PROJECT_ROOT / 'data' / 'interim' / 'activitiy recognition' / 'tesla_sentiment.csv'\n",
    "\n",
    "START = datetime(2024, 6, 1)\n",
    "END = datetime(2025, 7, 22)\n",
    "\n",
    "result_df = run_reddit_sentiment(\n",
    "    subreddit_name='wallstreetbets',\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    max_posts=2000,\n",
    "    output_csv=str(OUTPUT_CSV),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check Reddit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def connect_to_reddit():\n",
    "#     reddit = praw.Reddit(\n",
    "#         client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "#         client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "#         user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    "#     )\n",
    "#     return reddit\n",
    "\n",
    "# reddit = connect_to_reddit()\n",
    "\n",
    "# # Define the subreddit\n",
    "# subreddit = reddit.subreddit('wallstreetbets')\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# for submission in subreddit.hot(limit=1):\n",
    "#     attrs = dir(submission)\n",
    "#     df = pd.DataFrame(attrs, columns=['attribute'])\n",
    "#     display(df)\n",
    "    \n",
    "# df.to_csv('reddit_class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract NVDA text data from Reddit\n",
    "\n",
    "https://praw.readthedocs.io/en/latest/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS RESULTS\n",
      "============================================================\n",
      "Total posts analyzed: 490\n",
      "Date range: 2024-06-01 to 2025-10-16\n",
      "Average sentiment score: 0.794\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     317\n",
      "positive    107\n",
      "negative     66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Collection method distribution:\n",
      "collection_method\n",
      "search_nvda                85\n",
      "search_gpu                 67\n",
      "search_nvidia              62\n",
      "search_jensen huang        54\n",
      "search_blackwell           42\n",
      "search_nvidia ai           38\n",
      "search_rtx                 31\n",
      "search_nvidia drive        29\n",
      "new                        20\n",
      "search_cuda                15\n",
      "search_hopper              14\n",
      "search_h100                12\n",
      "search_jetson               6\n",
      "search_dali                 4\n",
      "search_dgx                  2\n",
      "hot                         2\n",
      "search_inference engine     2\n",
      "search_nvlink               2\n",
      "search_a100                 2\n",
      "search_omniverse            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Flair distribution:\n",
      "flair\n",
      "Discussion         144\n",
      "DD                  98\n",
      "News                87\n",
      "Gain                68\n",
      "YOLO                51\n",
      "Loss                18\n",
      "Meme                16\n",
      "Earnings Thread      5\n",
      "Chart                3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Daily post counts:\n",
      "date\n",
      "2024-06-03    2\n",
      "2024-06-04    1\n",
      "2024-06-05    1\n",
      "2024-06-06    1\n",
      "2024-06-10    1\n",
      "             ..\n",
      "2025-10-09    5\n",
      "2025-10-10    3\n",
      "2025-10-13    4\n",
      "2025-10-14    3\n",
      "2025-10-15    4\n",
      "Name: count, Length: 223, dtype: int64\n",
      "\n",
      "Top 5 posts by Reddit score:\n",
      "                                                 title  reddit_score  \\\n",
      "11                                   Enjoy the weekend         39527   \n",
      "242                                                  👀         27558   \n",
      "108   $10,526 to $1,500,000 in 5 months thanks Google!         24903   \n",
      "90                      $ORCL - Infinite money glitch.         20282   \n",
      "18   Bought NVDA in 2022 because I liked gaming. 1,...         15361   \n",
      "\n",
      "    sentiment  sentiment_score        date flair  \n",
      "11    neutral         0.900272  2025-10-10  Meme  \n",
      "242   neutral         0.000000  2025-03-14  Meme  \n",
      "108   neutral         0.480857  2025-09-03  Gain  \n",
      "90    neutral         0.904220  2025-09-15  Meme  \n",
      "18    neutral         0.884269  2025-10-09  Gain  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>collection_method</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1o7kitx</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-10-15 14:23:21</td>\n",
       "      <td>Is $NVDA due for jump back?</td>\n",
       "      <td>Is NVDA due for jump back No DD, pure instinct...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.87</td>\n",
       "      <td>43</td>\n",
       "      <td>WSBNoobie</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.861297</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1o7ib6m</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-10-15 13:01:50</td>\n",
       "      <td>LINC will flash before my eyes</td>\n",
       "      <td>LINC will flash before my eyes One day your li...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4</td>\n",
       "      <td>MaximumSafetyLLC</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.923048</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1o7954w</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-10-15 07:05:48</td>\n",
       "      <td>AHOY! We set sail on the Digital Ocean - DOCN ...</td>\n",
       "      <td>AHOY We set sail on the Digital Ocean DOCN 20k...</td>\n",
       "      <td>923</td>\n",
       "      <td>0.96</td>\n",
       "      <td>258</td>\n",
       "      <td>ChemaKyle</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.898752</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1o6yepl</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-10-14 20:51:56</td>\n",
       "      <td>AI may be a bubble, but the sentiment in China...</td>\n",
       "      <td>AI may be a bubble, but the sentiment in China...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>23</td>\n",
       "      <td>nat2r</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.827192</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1o6t2i7</td>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>2025-10-14 16:55:29</td>\n",
       "      <td>$SSYS: Certified to Print Drones, Aerospace pa...</td>\n",
       "      <td>SSYS Certified to Print Drones, Aerospace part...</td>\n",
       "      <td>73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>44</td>\n",
       "      <td>RoloBoat</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.693011</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date             datetime  \\\n",
       "0  1o7kitx  2025-10-15  2025-10-15 14:23:21   \n",
       "1  1o7ib6m  2025-10-15  2025-10-15 13:01:50   \n",
       "2  1o7954w  2025-10-15  2025-10-15 07:05:48   \n",
       "3  1o6yepl  2025-10-15  2025-10-14 20:51:56   \n",
       "4  1o6t2i7  2025-10-14  2025-10-14 16:55:29   \n",
       "\n",
       "                                               title  \\\n",
       "0                        Is $NVDA due for jump back?   \n",
       "1                     LINC will flash before my eyes   \n",
       "2  AHOY! We set sail on the Digital Ocean - DOCN ...   \n",
       "3  AI may be a bubble, but the sentiment in China...   \n",
       "4  $SSYS: Certified to Print Drones, Aerospace pa...   \n",
       "\n",
       "                                                text  reddit_score  \\\n",
       "0  Is NVDA due for jump back No DD, pure instinct...            64   \n",
       "1  LINC will flash before my eyes One day your li...             7   \n",
       "2  AHOY We set sail on the Digital Ocean DOCN 20k...           923   \n",
       "3  AI may be a bubble, but the sentiment in China...             0   \n",
       "4  SSYS Certified to Print Drones, Aerospace part...            73   \n",
       "\n",
       "   upvote_ratio  num_comments            author sentiment  sentiment_score  \\\n",
       "0          0.87            43         WSBNoobie   neutral         0.861297   \n",
       "1          0.82             4  MaximumSafetyLLC   neutral         0.923048   \n",
       "2          0.96           258         ChemaKyle   neutral         0.898752   \n",
       "3          0.41            23             nat2r   neutral         0.827192   \n",
       "4          0.90            44          RoloBoat   neutral         0.693011   \n",
       "\n",
       "                                           permalink collection_method flair  \n",
       "0  https://reddit.com/r/wallstreetbets/comments/1...               new  YOLO  \n",
       "1  https://reddit.com/r/wallstreetbets/comments/1...               new  YOLO  \n",
       "2  https://reddit.com/r/wallstreetbets/comments/1...               new    DD  \n",
       "3  https://reddit.com/r/wallstreetbets/comments/1...               new    DD  \n",
       "4  https://reddit.com/r/wallstreetbets/comments/1...               new    DD  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Updated: The function is likely now called run_reddit_sentiment based on the latest reddit_nvda_sentiment.py\n",
    "from models.reddit_nvda_sentiment import run_reddit_sentiment\n",
    "\n",
    "OUTPUT_CSV = PROJECT_ROOT / 'data' / 'interim' / 'activitiy_recognition' / 'nvda_sentiment_1016.csv'\n",
    "\n",
    "START = datetime(2024, 6, 1)\n",
    "END = datetime(2025, 10, 16)\n",
    "\n",
    "result_df = run_reddit_sentiment(\n",
    "    subreddit_name='wallstreetbets',\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    max_posts=2000,\n",
    "    output_csv=str(OUTPUT_CSV),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
