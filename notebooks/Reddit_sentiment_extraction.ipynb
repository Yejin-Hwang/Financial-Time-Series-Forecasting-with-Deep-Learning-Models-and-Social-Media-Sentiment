{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tsla text data from Reddit\n",
    "\n",
    "https://gcdi.commons.gc.cuny.edu/2024/11/01/web-scraping-with-python-and-the-reddit-api/\n",
    "See PRAW documentation: https://praw.readthedocs.io/en/latest/getting_started/configuration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS RESULTS\n",
      "============================================================\n",
      "Total posts analyzed: 526\n",
      "Date range: 2024-06-01 to 2025-07-22\n",
      "Average sentiment score: 0.803\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     346\n",
      "negative     93\n",
      "positive     87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Collection method distribution:\n",
      "collection_method\n",
      "search_elon musk            91\n",
      "search_full self driving    69\n",
      "search_ev                   60\n",
      "search_tesla                56\n",
      "search_tsla                 53\n",
      "search_elon                 42\n",
      "search_electric vehicle     39\n",
      "search_spacex               39\n",
      "search_robotaxi             30\n",
      "search_fsd                  17\n",
      "search_cybertruck           14\n",
      "search_battery day           6\n",
      "search_supercharger          5\n",
      "search_autopilot             3\n",
      "search_neuralink             1\n",
      "search_gigafactory           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Flair distribution:\n",
      "flair\n",
      "Discussion         157\n",
      "News               109\n",
      "DD                 107\n",
      "Gain                80\n",
      "YOLO                49\n",
      "Loss                15\n",
      "Meme                 6\n",
      "Shitpost             2\n",
      "Earnings Thread      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Daily post counts:\n",
      "date\n",
      "2024-06-04    1\n",
      "2024-06-05    1\n",
      "2024-06-07    1\n",
      "2024-06-10    4\n",
      "2024-06-11    1\n",
      "             ..\n",
      "2025-07-15    1\n",
      "2025-07-16    2\n",
      "2025-07-17    4\n",
      "2025-07-18    4\n",
      "2025-07-21    6\n",
      "Name: count, Length: 222, dtype: int64\n",
      "\n",
      "Top 5 posts by Reddit score:\n",
      "                                                 title  reddit_score  \\\n",
      "208  [Fortune] Elon Musk's Tesla reportedly halts C...         24730   \n",
      "359  $80,000 to $1.12M in 7 days. Thank you Elon Mu...         19487   \n",
      "279  Trump says he will declare national energy eme...         17133   \n",
      "63                   Is this spelling that on purpose?         15817   \n",
      "51   I tried to tell my Father, but he was hell ben...         12588   \n",
      "\n",
      "    sentiment  sentiment_score        date       flair  \n",
      "208  negative         0.949766  2025-03-14        News  \n",
      "359   neutral         0.883343  2024-11-11        Gain  \n",
      "279  negative         0.557780  2025-01-21        News  \n",
      "63    neutral         0.900921  2025-06-20  Discussion  \n",
      "51    neutral         0.637736  2025-06-25        Gain  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>collection_method</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1m5yp45</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 18:36:38</td>\n",
       "      <td>Muted Results but Booming Guidance: NVDA Q2 Ea...</td>\n",
       "      <td>Muted Results but Booming Guidance NVDA Q2 Ear...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.89</td>\n",
       "      <td>16</td>\n",
       "      <td>hazxrrd</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.878628</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_full self driving</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1m5nb20</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 11:18:41</td>\n",
       "      <td>If itâ€™s good enough to screenshot itâ€™s good en...</td>\n",
       "      <td>If it s good enough to screenshot it s good en...</td>\n",
       "      <td>535</td>\n",
       "      <td>0.95</td>\n",
       "      <td>55</td>\n",
       "      <td>Phazem</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.503953</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tsla</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1m5lmlv</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 10:15:55</td>\n",
       "      <td>OPEN your eyes</td>\n",
       "      <td>OPEN your eyes Hold the fucking line</td>\n",
       "      <td>231</td>\n",
       "      <td>0.95</td>\n",
       "      <td>14</td>\n",
       "      <td>Delicious-Cress6983</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.857597</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tesla</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1m46wiu</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:59:40</td>\n",
       "      <td>$14k in a day (TSLA Puts)</td>\n",
       "      <td>14k in a day TSLA Puts</td>\n",
       "      <td>67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10</td>\n",
       "      <td>TrueButterfly3908</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tsla</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1m46fuj</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:39:06</td>\n",
       "      <td>Googleâ€™s AI Awakening: Earnings Bull Case</td>\n",
       "      <td>Google s AI Awakening Earnings Bull Case Beyon...</td>\n",
       "      <td>300</td>\n",
       "      <td>0.88</td>\n",
       "      <td>150</td>\n",
       "      <td>wanderingtofu</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.687717</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_full self driving</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date             datetime  \\\n",
       "0  1m5yp45  2025-07-21  2025-07-21 18:36:38   \n",
       "1  1m5nb20  2025-07-21  2025-07-21 11:18:41   \n",
       "2  1m5lmlv  2025-07-21  2025-07-21 10:15:55   \n",
       "3  1m46wiu  2025-07-21  2025-07-19 15:59:40   \n",
       "4  1m46fuj  2025-07-21  2025-07-19 15:39:06   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muted Results but Booming Guidance: NVDA Q2 Ea...   \n",
       "1  If itâ€™s good enough to screenshot itâ€™s good en...   \n",
       "2                                     OPEN your eyes   \n",
       "3                          $14k in a day (TSLA Puts)   \n",
       "4          Googleâ€™s AI Awakening: Earnings Bull Case   \n",
       "\n",
       "                                                text  reddit_score  \\\n",
       "0  Muted Results but Booming Guidance NVDA Q2 Ear...            57   \n",
       "1  If it s good enough to screenshot it s good en...           535   \n",
       "2               OPEN your eyes Hold the fucking line           231   \n",
       "3                             14k in a day TSLA Puts            67   \n",
       "4  Google s AI Awakening Earnings Bull Case Beyon...           300   \n",
       "\n",
       "   upvote_ratio  num_comments               author sentiment  sentiment_score  \\\n",
       "0          0.89            16              hazxrrd  negative         0.878628   \n",
       "1          0.95            55               Phazem  positive         0.503953   \n",
       "2          0.95            14  Delicious-Cress6983   neutral         0.857597   \n",
       "3          0.86            10    TrueButterfly3908   neutral         0.855079   \n",
       "4          0.88           150        wanderingtofu   neutral         0.687717   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "1  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "2  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "3  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "4  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "\n",
       "          collection_method       flair  \n",
       "0  search_full self driving          DD  \n",
       "1               search_tsla        YOLO  \n",
       "2              search_tesla        YOLO  \n",
       "3               search_tsla        Gain  \n",
       "4  search_full self driving  Discussion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delegate to models/reddit_sentiment.py\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from models.reddit_tsla_sentiment import run_reddit_tsla_sentiment as run_reddit_sentiment\n",
    "\n",
    "OUTPUT_CSV = PROJECT_ROOT / 'data' / 'interim' / 'activitiy recognition' / 'tesla_sentiment.csv'\n",
    "\n",
    "START = datetime(2024, 6, 1)\n",
    "END = datetime(2025, 7, 22)\n",
    "\n",
    "result_df = run_reddit_sentiment(\n",
    "    subreddit_name='wallstreetbets',\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    max_posts=2000,\n",
    "    output_csv=str(OUTPUT_CSV),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check Reddit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def connect_to_reddit():\n",
    "#     reddit = praw.Reddit(\n",
    "#         client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "#         client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "#         user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    "#     )\n",
    "#     return reddit\n",
    "\n",
    "# reddit = connect_to_reddit()\n",
    "\n",
    "# # Define the subreddit\n",
    "# subreddit = reddit.subreddit('wallstreetbets')\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# for submission in subreddit.hot(limit=1):\n",
    "#     attrs = dir(submission)\n",
    "#     df = pd.DataFrame(attrs, columns=['attribute'])\n",
    "#     display(df)\n",
    "    \n",
    "# df.to_csv('reddit_class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract NVDA text data from Reddit\n",
    "\n",
    "https://praw.readthedocs.io/en/latest/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS RESULTS\n",
      "============================================================\n",
      "Total posts analyzed: 490\n",
      "Date range: 2024-06-01 to 2025-10-16\n",
      "Average sentiment score: 0.794\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     317\n",
      "positive    107\n",
      "negative     66\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Collection method distribution:\n",
      "collection_method\n",
      "search_nvda                85\n",
      "search_gpu                 67\n",
      "search_nvidia              62\n",
      "search_jensen huang        54\n",
      "search_blackwell           42\n",
      "search_nvidia ai           38\n",
      "search_rtx                 31\n",
      "search_nvidia drive        29\n",
      "new                        20\n",
      "search_cuda                15\n",
      "search_hopper              14\n",
      "search_h100                12\n",
      "search_jetson               6\n",
      "search_dali                 4\n",
      "search_dgx                  2\n",
      "hot                         2\n",
      "search_inference engine     2\n",
      "search_nvlink               2\n",
      "search_a100                 2\n",
      "search_omniverse            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Flair distribution:\n",
      "flair\n",
      "Discussion         144\n",
      "DD                  98\n",
      "News                87\n",
      "Gain                68\n",
      "YOLO                51\n",
      "Loss                18\n",
      "Meme                16\n",
      "Earnings Thread      5\n",
      "Chart                3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Daily post counts:\n",
      "date\n",
      "2024-06-03    2\n",
      "2024-06-04    1\n",
      "2024-06-05    1\n",
      "2024-06-06    1\n",
      "2024-06-10    1\n",
      "             ..\n",
      "2025-10-09    5\n",
      "2025-10-10    3\n",
      "2025-10-13    4\n",
      "2025-10-14    3\n",
      "2025-10-15    4\n",
      "Name: count, Length: 223, dtype: int64\n",
      "\n",
      "Top 5 posts by Reddit score:\n",
      "                                                 title  reddit_score  \\\n",
      "11                                   Enjoy the weekend         39527   \n",
      "242                                                  ðŸ‘€         27558   \n",
      "108   $10,526 to $1,500,000 in 5 months thanks Google!         24903   \n",
      "90                      $ORCL - Infinite money glitch.         20282   \n",
      "18   Bought NVDA in 2022 because I liked gaming. 1,...         15361   \n",
      "\n",
      "    sentiment  sentiment_score        date flair  \n",
      "11    neutral         0.900272  2025-10-10  Meme  \n",
      "242   neutral         0.000000  2025-03-14  Meme  \n",
      "108   neutral         0.480857  2025-09-03  Gain  \n",
      "90    neutral         0.904220  2025-09-15  Meme  \n",
      "18    neutral         0.884269  2025-10-09  Gain  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>collection_method</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1o7kitx</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-10-15 14:23:21</td>\n",
       "      <td>Is $NVDA due for jump back?</td>\n",
       "      <td>Is NVDA due for jump back No DD, pure instinct...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.87</td>\n",
       "      <td>43</td>\n",
       "      <td>WSBNoobie</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.861297</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1o7ib6m</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-10-15 13:01:50</td>\n",
       "      <td>LINC will flash before my eyes</td>\n",
       "      <td>LINC will flash before my eyes One day your li...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.82</td>\n",
       "      <td>4</td>\n",
       "      <td>MaximumSafetyLLC</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.923048</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1o7954w</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-10-15 07:05:48</td>\n",
       "      <td>AHOY! We set sail on the Digital Ocean - DOCN ...</td>\n",
       "      <td>AHOY We set sail on the Digital Ocean DOCN 20k...</td>\n",
       "      <td>923</td>\n",
       "      <td>0.96</td>\n",
       "      <td>258</td>\n",
       "      <td>ChemaKyle</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.898752</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1o6yepl</td>\n",
       "      <td>2025-10-15</td>\n",
       "      <td>2025-10-14 20:51:56</td>\n",
       "      <td>AI may be a bubble, but the sentiment in China...</td>\n",
       "      <td>AI may be a bubble, but the sentiment in China...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>23</td>\n",
       "      <td>nat2r</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.827192</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1o6t2i7</td>\n",
       "      <td>2025-10-14</td>\n",
       "      <td>2025-10-14 16:55:29</td>\n",
       "      <td>$SSYS: Certified to Print Drones, Aerospace pa...</td>\n",
       "      <td>SSYS Certified to Print Drones, Aerospace part...</td>\n",
       "      <td>73</td>\n",
       "      <td>0.90</td>\n",
       "      <td>44</td>\n",
       "      <td>RoloBoat</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.693011</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date             datetime  \\\n",
       "0  1o7kitx  2025-10-15  2025-10-15 14:23:21   \n",
       "1  1o7ib6m  2025-10-15  2025-10-15 13:01:50   \n",
       "2  1o7954w  2025-10-15  2025-10-15 07:05:48   \n",
       "3  1o6yepl  2025-10-15  2025-10-14 20:51:56   \n",
       "4  1o6t2i7  2025-10-14  2025-10-14 16:55:29   \n",
       "\n",
       "                                               title  \\\n",
       "0                        Is $NVDA due for jump back?   \n",
       "1                     LINC will flash before my eyes   \n",
       "2  AHOY! We set sail on the Digital Ocean - DOCN ...   \n",
       "3  AI may be a bubble, but the sentiment in China...   \n",
       "4  $SSYS: Certified to Print Drones, Aerospace pa...   \n",
       "\n",
       "                                                text  reddit_score  \\\n",
       "0  Is NVDA due for jump back No DD, pure instinct...            64   \n",
       "1  LINC will flash before my eyes One day your li...             7   \n",
       "2  AHOY We set sail on the Digital Ocean DOCN 20k...           923   \n",
       "3  AI may be a bubble, but the sentiment in China...             0   \n",
       "4  SSYS Certified to Print Drones, Aerospace part...            73   \n",
       "\n",
       "   upvote_ratio  num_comments            author sentiment  sentiment_score  \\\n",
       "0          0.87            43         WSBNoobie   neutral         0.861297   \n",
       "1          0.82             4  MaximumSafetyLLC   neutral         0.923048   \n",
       "2          0.96           258         ChemaKyle   neutral         0.898752   \n",
       "3          0.41            23             nat2r   neutral         0.827192   \n",
       "4          0.90            44          RoloBoat   neutral         0.693011   \n",
       "\n",
       "                                           permalink collection_method flair  \n",
       "0  https://reddit.com/r/wallstreetbets/comments/1...               new  YOLO  \n",
       "1  https://reddit.com/r/wallstreetbets/comments/1...               new  YOLO  \n",
       "2  https://reddit.com/r/wallstreetbets/comments/1...               new    DD  \n",
       "3  https://reddit.com/r/wallstreetbets/comments/1...               new    DD  \n",
       "4  https://reddit.com/r/wallstreetbets/comments/1...               new    DD  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Updated: The function is likely now called run_reddit_sentiment based on the latest reddit_nvda_sentiment.py\n",
    "from models.reddit_nvda_sentiment import run_reddit_sentiment\n",
    "\n",
    "OUTPUT_CSV = PROJECT_ROOT / 'data' / 'interim' / 'activitiy_recognition' / 'nvda_sentiment_1016.csv'\n",
    "\n",
    "START = datetime(2024, 6, 1)\n",
    "END = datetime(2025, 10, 16)\n",
    "\n",
    "result_df = run_reddit_sentiment(\n",
    "    subreddit_name='wallstreetbets',\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    max_posts=2000,\n",
    "    output_csv=str(OUTPUT_CSV),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYND "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS RESULTS (BYND)\n",
      "============================================================\n",
      "Total posts analyzed: 83\n",
      "Date range: 2025-06-01 to 2025-10-24\n",
      "Average sentiment score: 0.800\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     69\n",
      "positive     7\n",
      "negative     7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Collection method distribution:\n",
      "collection_method\n",
      "new                               27\n",
      "search_options flow               18\n",
      "search_short squeeze              16\n",
      "search_bynd                        7\n",
      "search_plant based meat            6\n",
      "search_borrow fee                  5\n",
      "search_beyond meat                 3\n",
      "search_burger king plant-based     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Flair distribution:\n",
      "flair\n",
      "YOLO          31\n",
      "DD            25\n",
      "Gain          12\n",
      "Discussion     6\n",
      "Meme           4\n",
      "Loss           3\n",
      "News           2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Daily post counts:\n",
      "date\n",
      "2025-06-02     2\n",
      "2025-06-04     2\n",
      "2025-06-06     1\n",
      "2025-06-09     4\n",
      "2025-06-11     1\n",
      "2025-06-27     1\n",
      "2025-07-03     1\n",
      "2025-07-10     1\n",
      "2025-07-17     1\n",
      "2025-07-22     1\n",
      "2025-07-23     2\n",
      "2025-07-28     2\n",
      "2025-07-29     1\n",
      "2025-07-30     1\n",
      "2025-08-04     1\n",
      "2025-08-05     1\n",
      "2025-08-13     1\n",
      "2025-08-14     1\n",
      "2025-08-15     1\n",
      "2025-08-18     3\n",
      "2025-08-25     1\n",
      "2025-09-09     1\n",
      "2025-09-10     1\n",
      "2025-09-15     1\n",
      "2025-09-16     1\n",
      "2025-09-19     2\n",
      "2025-09-22     1\n",
      "2025-09-29     3\n",
      "2025-10-06     2\n",
      "2025-10-08     1\n",
      "2025-10-09     1\n",
      "2025-10-10     1\n",
      "2025-10-14     1\n",
      "2025-10-15     1\n",
      "2025-10-21     1\n",
      "2025-10-22    26\n",
      "2025-10-23     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 posts by Reddit score:\n",
      "                                   title  reddit_score sentiment  \\\n",
      "17    BYND Bagholders that bought at $7+         19883   neutral   \n",
      "34                      BYND BUY @ $7.50         11251   neutral   \n",
      "13                    Canâ€™t make this up         10495   neutral   \n",
      "55  How Beyond Meat Portfolios look like          6811   neutral   \n",
      "14                       Is it too soon?          6509   neutral   \n",
      "\n",
      "    sentiment_score        date flair  \n",
      "17         0.913120  2025-10-22  Meme  \n",
      "34         0.773872  2025-10-22  YOLO  \n",
      "13         0.562646  2025-10-22  Meme  \n",
      "55         0.932233  2025-08-18  Meme  \n",
      "14         0.680010  2025-10-22  Meme  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>collection_method</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1oedh23</td>\n",
       "      <td>2025-10-23</td>\n",
       "      <td>2025-10-23 14:59:55</td>\n",
       "      <td>YOLO Beyond Meat 7000 contracts $350,000 position</td>\n",
       "      <td>YOLO Beyond Meat 7000 contracts 350,000 positi...</td>\n",
       "      <td>1466</td>\n",
       "      <td>0.95</td>\n",
       "      <td>274</td>\n",
       "      <td>wanderingtofu</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.915307</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1oeb66h</td>\n",
       "      <td>2025-10-23</td>\n",
       "      <td>2025-10-23 13:31:17</td>\n",
       "      <td>MSOS- Cannabis DD</td>\n",
       "      <td>MSOS Cannabis DD Trump last month said he ll l...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.75</td>\n",
       "      <td>37</td>\n",
       "      <td>AdministrativeWar647</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1oea9vq</td>\n",
       "      <td>2025-10-23</td>\n",
       "      <td>2025-10-23 12:57:28</td>\n",
       "      <td>Long BYND</td>\n",
       "      <td>Long BYND</td>\n",
       "      <td>1734</td>\n",
       "      <td>0.91</td>\n",
       "      <td>450</td>\n",
       "      <td>Trick_Raccoon_HTX</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.901631</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1oe1lor</td>\n",
       "      <td>2025-10-23</td>\n",
       "      <td>2025-10-23 07:12:03</td>\n",
       "      <td>idc</td>\n",
       "      <td>idc</td>\n",
       "      <td>1263</td>\n",
       "      <td>0.94</td>\n",
       "      <td>263</td>\n",
       "      <td>No_Yesterday5746</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.916703</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_beyond meat</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1odw7lb</td>\n",
       "      <td>2025-10-23</td>\n",
       "      <td>2025-10-23 01:42:37</td>\n",
       "      <td>Thanks BYND, QBTS and BITF</td>\n",
       "      <td>Thanks BYND, QBTS and BITF Started early octob...</td>\n",
       "      <td>283</td>\n",
       "      <td>0.93</td>\n",
       "      <td>59</td>\n",
       "      <td>Darkfury44</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.866350</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>new</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date             datetime  \\\n",
       "0  1oedh23  2025-10-23  2025-10-23 14:59:55   \n",
       "1  1oeb66h  2025-10-23  2025-10-23 13:31:17   \n",
       "2  1oea9vq  2025-10-23  2025-10-23 12:57:28   \n",
       "3  1oe1lor  2025-10-23  2025-10-23 07:12:03   \n",
       "4  1odw7lb  2025-10-23  2025-10-23 01:42:37   \n",
       "\n",
       "                                               title  \\\n",
       "0  YOLO Beyond Meat 7000 contracts $350,000 position   \n",
       "1                                  MSOS- Cannabis DD   \n",
       "2                                          Long BYND   \n",
       "3                                                idc   \n",
       "4                         Thanks BYND, QBTS and BITF   \n",
       "\n",
       "                                                text  reddit_score  \\\n",
       "0  YOLO Beyond Meat 7000 contracts 350,000 positi...          1466   \n",
       "1  MSOS Cannabis DD Trump last month said he ll l...            26   \n",
       "2                                          Long BYND          1734   \n",
       "3                                                idc          1263   \n",
       "4  Thanks BYND, QBTS and BITF Started early octob...           283   \n",
       "\n",
       "   upvote_ratio  num_comments                author sentiment  \\\n",
       "0          0.95           274         wanderingtofu   neutral   \n",
       "1          0.75            37  AdministrativeWar647   neutral   \n",
       "2          0.91           450     Trick_Raccoon_HTX   neutral   \n",
       "3          0.94           263      No_Yesterday5746   neutral   \n",
       "4          0.93            59            Darkfury44   neutral   \n",
       "\n",
       "   sentiment_score                                          permalink  \\\n",
       "0         0.915307  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "1         0.856743  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "2         0.901631  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "3         0.916703  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "4         0.866350  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "\n",
       "    collection_method flair  \n",
       "0                 new  YOLO  \n",
       "1                 new    DD  \n",
       "2                 new  YOLO  \n",
       "3  search_beyond meat  YOLO  \n",
       "4                 new  Gain  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Updated: The function is likely now called run_reddit_sentiment based on the latest reddit_nvda_sentiment.py\n",
    "from models.reddit_bynd_sentiment import run_reddit_sentiment\n",
    "\n",
    "OUTPUT_CSV = PROJECT_ROOT / 'data' / 'interim' / 'activitiy_recognition' / 'bynd_sentiment_1024.csv'\n",
    "\n",
    "START = datetime(2025, 6, 1)\n",
    "END = datetime(2025, 10, 24)\n",
    "\n",
    "result_df = run_reddit_sentiment(\n",
    "    subreddit_name='wallstreetbets',\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    max_posts=2000,\n",
    "    output_csv=str(OUTPUT_CSV),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
