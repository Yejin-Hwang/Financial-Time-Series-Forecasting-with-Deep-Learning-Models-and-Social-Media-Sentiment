{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tsla text data from Reddit\n",
    "\n",
    "https://gcdi.commons.gc.cuny.edu/2024/11/01/web-scraping-with-python-and-the-reddit-api/\n",
    "See PRAW documentation: https://praw.readthedocs.io/en/latest/getting_started/configuration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS RESULTS\n",
      "============================================================\n",
      "Total posts analyzed: 526\n",
      "Date range: 2024-06-01 to 2025-07-22\n",
      "Average sentiment score: 0.803\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     346\n",
      "negative     93\n",
      "positive     87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Collection method distribution:\n",
      "collection_method\n",
      "search_elon musk            91\n",
      "search_full self driving    69\n",
      "search_ev                   60\n",
      "search_tesla                56\n",
      "search_tsla                 53\n",
      "search_elon                 42\n",
      "search_electric vehicle     39\n",
      "search_spacex               39\n",
      "search_robotaxi             30\n",
      "search_fsd                  17\n",
      "search_cybertruck           14\n",
      "search_battery day           6\n",
      "search_supercharger          5\n",
      "search_autopilot             3\n",
      "search_neuralink             1\n",
      "search_gigafactory           1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Flair distribution:\n",
      "flair\n",
      "Discussion         157\n",
      "News               109\n",
      "DD                 107\n",
      "Gain                80\n",
      "YOLO                49\n",
      "Loss                15\n",
      "Meme                 6\n",
      "Shitpost             2\n",
      "Earnings Thread      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Daily post counts:\n",
      "date\n",
      "2024-06-04    1\n",
      "2024-06-05    1\n",
      "2024-06-07    1\n",
      "2024-06-10    4\n",
      "2024-06-11    1\n",
      "             ..\n",
      "2025-07-15    1\n",
      "2025-07-16    2\n",
      "2025-07-17    4\n",
      "2025-07-18    4\n",
      "2025-07-21    6\n",
      "Name: count, Length: 222, dtype: int64\n",
      "\n",
      "Top 5 posts by Reddit score:\n",
      "                                                 title  reddit_score  \\\n",
      "208  [Fortune] Elon Musk's Tesla reportedly halts C...         24730   \n",
      "359  $80,000 to $1.12M in 7 days. Thank you Elon Mu...         19487   \n",
      "279  Trump says he will declare national energy eme...         17133   \n",
      "63                   Is this spelling that on purpose?         15817   \n",
      "51   I tried to tell my Father, but he was hell ben...         12588   \n",
      "\n",
      "    sentiment  sentiment_score        date       flair  \n",
      "208  negative         0.949766  2025-03-14        News  \n",
      "359   neutral         0.883343  2024-11-11        Gain  \n",
      "279  negative         0.557780  2025-01-21        News  \n",
      "63    neutral         0.900921  2025-06-20  Discussion  \n",
      "51    neutral         0.637736  2025-06-25        Gain  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>collection_method</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1m5yp45</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 18:36:38</td>\n",
       "      <td>Muted Results but Booming Guidance: NVDA Q2 Ea...</td>\n",
       "      <td>Muted Results but Booming Guidance NVDA Q2 Ear...</td>\n",
       "      <td>57</td>\n",
       "      <td>0.89</td>\n",
       "      <td>16</td>\n",
       "      <td>hazxrrd</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.878628</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_full self driving</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1m5nb20</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 11:18:41</td>\n",
       "      <td>If it’s good enough to screenshot it’s good en...</td>\n",
       "      <td>If it s good enough to screenshot it s good en...</td>\n",
       "      <td>535</td>\n",
       "      <td>0.95</td>\n",
       "      <td>55</td>\n",
       "      <td>Phazem</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.503953</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tsla</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1m5lmlv</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 10:15:55</td>\n",
       "      <td>OPEN your eyes</td>\n",
       "      <td>OPEN your eyes Hold the fucking line</td>\n",
       "      <td>231</td>\n",
       "      <td>0.95</td>\n",
       "      <td>14</td>\n",
       "      <td>Delicious-Cress6983</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.857597</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tesla</td>\n",
       "      <td>YOLO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1m46wiu</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:59:40</td>\n",
       "      <td>$14k in a day (TSLA Puts)</td>\n",
       "      <td>14k in a day TSLA Puts</td>\n",
       "      <td>67</td>\n",
       "      <td>0.86</td>\n",
       "      <td>10</td>\n",
       "      <td>TrueButterfly3908</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.855079</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_tsla</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1m46fuj</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:39:06</td>\n",
       "      <td>Google’s AI Awakening: Earnings Bull Case</td>\n",
       "      <td>Google s AI Awakening Earnings Bull Case Beyon...</td>\n",
       "      <td>300</td>\n",
       "      <td>0.88</td>\n",
       "      <td>150</td>\n",
       "      <td>wanderingtofu</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.687717</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_full self driving</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date             datetime  \\\n",
       "0  1m5yp45  2025-07-21  2025-07-21 18:36:38   \n",
       "1  1m5nb20  2025-07-21  2025-07-21 11:18:41   \n",
       "2  1m5lmlv  2025-07-21  2025-07-21 10:15:55   \n",
       "3  1m46wiu  2025-07-21  2025-07-19 15:59:40   \n",
       "4  1m46fuj  2025-07-21  2025-07-19 15:39:06   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muted Results but Booming Guidance: NVDA Q2 Ea...   \n",
       "1  If it’s good enough to screenshot it’s good en...   \n",
       "2                                     OPEN your eyes   \n",
       "3                          $14k in a day (TSLA Puts)   \n",
       "4          Google’s AI Awakening: Earnings Bull Case   \n",
       "\n",
       "                                                text  reddit_score  \\\n",
       "0  Muted Results but Booming Guidance NVDA Q2 Ear...            57   \n",
       "1  If it s good enough to screenshot it s good en...           535   \n",
       "2               OPEN your eyes Hold the fucking line           231   \n",
       "3                             14k in a day TSLA Puts            67   \n",
       "4  Google s AI Awakening Earnings Bull Case Beyon...           300   \n",
       "\n",
       "   upvote_ratio  num_comments               author sentiment  sentiment_score  \\\n",
       "0          0.89            16              hazxrrd  negative         0.878628   \n",
       "1          0.95            55               Phazem  positive         0.503953   \n",
       "2          0.95            14  Delicious-Cress6983   neutral         0.857597   \n",
       "3          0.86            10    TrueButterfly3908   neutral         0.855079   \n",
       "4          0.88           150        wanderingtofu   neutral         0.687717   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "1  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "2  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "3  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "4  https://reddit.com/r/wallstreetbets/comments/1...   \n",
       "\n",
       "          collection_method       flair  \n",
       "0  search_full self driving          DD  \n",
       "1               search_tsla        YOLO  \n",
       "2              search_tesla        YOLO  \n",
       "3               search_tsla        Gain  \n",
       "4  search_full self driving  Discussion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delegate to models/reddit_sentiment.py\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from models.reddit_tsla_sentiment import run_reddit_tsla_sentiment as run_reddit_sentiment\n",
    "\n",
    "OUTPUT_CSV = PROJECT_ROOT / 'data' / 'interim' / 'activitiy recognition' / 'tesla_sentiment.csv'\n",
    "\n",
    "START = datetime(2024, 6, 1)\n",
    "END = datetime(2025, 7, 22)\n",
    "\n",
    "result_df = run_reddit_sentiment(\n",
    "    subreddit_name='wallstreetbets',\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    max_posts=2000,\n",
    "    output_csv=str(OUTPUT_CSV),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check Reddit class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def connect_to_reddit():\n",
    "#     reddit = praw.Reddit(\n",
    "#         client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "#         client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "#         user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    "#     )\n",
    "#     return reddit\n",
    "\n",
    "# reddit = connect_to_reddit()\n",
    "\n",
    "# # Define the subreddit\n",
    "# subreddit = reddit.subreddit('wallstreetbets')\n",
    "\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# for submission in subreddit.hot(limit=1):\n",
    "#     attrs = dir(submission)\n",
    "#     df = pd.DataFrame(attrs, columns=['attribute'])\n",
    "#     display(df)\n",
    "    \n",
    "# df.to_csv('reddit_class')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract NVDA text data from Reddit\n",
    "\n",
    "https://praw.readthedocs.io/en/latest/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS RESULTS\n",
      "============================================================\n",
      "Total posts analyzed: 327\n",
      "Date range: 2024-06-01 to 2025-07-22\n",
      "Average sentiment score: 0.795\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "neutral     203\n",
      "positive     80\n",
      "negative     44\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Collection method distribution:\n",
      "collection_method\n",
      "search_gpu                 60\n",
      "search_jensen huang        52\n",
      "search_nvidia ai           42\n",
      "search_blackwell           40\n",
      "search_rtx                 30\n",
      "search_nvidia drive        29\n",
      "search_cuda                15\n",
      "search_nvidia              14\n",
      "search_hopper              14\n",
      "search_h100                12\n",
      "search_jetson               6\n",
      "search_dali                 4\n",
      "search_dgx                  2\n",
      "search_inference engine     2\n",
      "search_nvlink               2\n",
      "search_a100                 2\n",
      "search_omniverse            1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Flair distribution:\n",
      "flair\n",
      "Discussion         130\n",
      "DD                  76\n",
      "News                72\n",
      "Gain                15\n",
      "YOLO                14\n",
      "Meme                 8\n",
      "Loss                 5\n",
      "Earnings Thread      4\n",
      "Chart                3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Daily post counts:\n",
      "date\n",
      "2024-06-03     2\n",
      "2024-06-04     1\n",
      "2024-06-05     1\n",
      "2024-06-06     1\n",
      "2024-06-10     1\n",
      "              ..\n",
      "2025-07-11     1\n",
      "2025-07-15    11\n",
      "2025-07-16     1\n",
      "2025-07-18     2\n",
      "2025-07-21     3\n",
      "Name: count, Length: 173, dtype: int64\n",
      "\n",
      "Top 5 posts by Reddit score:\n",
      "                                                 title  reddit_score  \\\n",
      "74                                                   👀         27570   \n",
      "108  “DeepSeek . . . reportedly has 50,000 Nvidia G...         11360   \n",
      "12                  I did the thing (NVDA 18,500% ROI)         10047   \n",
      "251   How many of you bought the dip and quit wendy’s?          9047   \n",
      "141  It's pretty wild to say, but Intel now has the...          5848   \n",
      "\n",
      "    sentiment  sentiment_score        date       flair  \n",
      "74    neutral         0.000000  2025-03-14        Meme  \n",
      "108  negative         0.933937  2025-02-03        News  \n",
      "12    neutral         0.868282  2025-07-15        Gain  \n",
      "251  negative         0.532193  2024-08-09  Discussion  \n",
      "141   neutral         0.803346  2024-12-23        News  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>reddit_score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>collection_method</th>\n",
       "      <th>flair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1m5yp45</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21 18:36:38</td>\n",
       "      <td>Muted Results but Booming Guidance: NVDA Q2 Ea...</td>\n",
       "      <td>Muted Results but Booming Guidance NVDA Q2 Ear...</td>\n",
       "      <td>53</td>\n",
       "      <td>0.87</td>\n",
       "      <td>16</td>\n",
       "      <td>hazxrrd</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.878628</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_blackwell</td>\n",
       "      <td>DD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1m46fuj</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 15:39:06</td>\n",
       "      <td>Google’s AI Awakening: Earnings Bull Case</td>\n",
       "      <td>Google s AI Awakening Earnings Bull Case Beyon...</td>\n",
       "      <td>302</td>\n",
       "      <td>0.88</td>\n",
       "      <td>150</td>\n",
       "      <td>wanderingtofu</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.687717</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_nvidia</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1m3q7ci</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-19 02:27:37</td>\n",
       "      <td>Asking again, did I get lucky?</td>\n",
       "      <td>Asking again, did I get lucky Live and learn I...</td>\n",
       "      <td>156</td>\n",
       "      <td>0.84</td>\n",
       "      <td>57</td>\n",
       "      <td>DifficultElk5474</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.889792</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_nvidia</td>\n",
       "      <td>Gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1m37q5m</td>\n",
       "      <td>2025-07-18</td>\n",
       "      <td>2025-07-18 11:59:46</td>\n",
       "      <td>Who else is investing in the MAMACITA portfolio?</td>\n",
       "      <td>Who else is investing in the MAMACITA portfoli...</td>\n",
       "      <td>611</td>\n",
       "      <td>0.88</td>\n",
       "      <td>136</td>\n",
       "      <td>elonthegenerous</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.923651</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_nvidia</td>\n",
       "      <td>Discussion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1m32mvr</td>\n",
       "      <td>2025-07-18</td>\n",
       "      <td>2025-07-18 08:40:48</td>\n",
       "      <td>Weekly Earnings Thread 7/21 - 7/25</td>\n",
       "      <td>Weekly Earnings Thread 7 21 7 25</td>\n",
       "      <td>306</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2284</td>\n",
       "      <td>OSRSkarma</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.885751</td>\n",
       "      <td>https://reddit.com/r/wallstreetbets/comments/1...</td>\n",
       "      <td>search_rtx</td>\n",
       "      <td>Earnings Thread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id        date             datetime  \\\n",
       "0  1m5yp45  2025-07-21  2025-07-21 18:36:38   \n",
       "1  1m46fuj  2025-07-21  2025-07-19 15:39:06   \n",
       "2  1m3q7ci  2025-07-21  2025-07-19 02:27:37   \n",
       "3  1m37q5m  2025-07-18  2025-07-18 11:59:46   \n",
       "4  1m32mvr  2025-07-18  2025-07-18 08:40:48   \n",
       "\n",
       "                                               title  \\\n",
       "0  Muted Results but Booming Guidance: NVDA Q2 Ea...   \n",
       "1          Google’s AI Awakening: Earnings Bull Case   \n",
       "2                     Asking again, did I get lucky?   \n",
       "3   Who else is investing in the MAMACITA portfolio?   \n",
       "4                 Weekly Earnings Thread 7/21 - 7/25   \n",
       "\n",
       "                                                text  reddit_score  \\\n",
       "0  Muted Results but Booming Guidance NVDA Q2 Ear...            53   \n",
       "1  Google s AI Awakening Earnings Bull Case Beyon...           302   \n",
       "2  Asking again, did I get lucky Live and learn I...           156   \n",
       "3  Who else is investing in the MAMACITA portfoli...           611   \n",
       "4                   Weekly Earnings Thread 7 21 7 25           306   \n",
       "\n",
       "   upvote_ratio  num_comments            author sentiment  sentiment_score  \\\n",
       "0          0.87            16           hazxrrd  negative         0.878628   \n",
       "1          0.88           150     wanderingtofu   neutral         0.687717   \n",
       "2          0.84            57  DifficultElk5474   neutral         0.889792   \n",
       "3          0.88           136   elonthegenerous   neutral         0.923651   \n",
       "4          0.98          2284         OSRSkarma   neutral         0.885751   \n",
       "\n",
       "                                           permalink collection_method  \\\n",
       "0  https://reddit.com/r/wallstreetbets/comments/1...  search_blackwell   \n",
       "1  https://reddit.com/r/wallstreetbets/comments/1...     search_nvidia   \n",
       "2  https://reddit.com/r/wallstreetbets/comments/1...     search_nvidia   \n",
       "3  https://reddit.com/r/wallstreetbets/comments/1...     search_nvidia   \n",
       "4  https://reddit.com/r/wallstreetbets/comments/1...        search_rtx   \n",
       "\n",
       "             flair  \n",
       "0               DD  \n",
       "1       Discussion  \n",
       "2             Gain  \n",
       "3       Discussion  \n",
       "4  Earnings Thread  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "PROJECT_ROOT = cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Updated: The function is likely now called run_reddit_sentiment based on the latest reddit_nvda_sentiment.py\n",
    "from models.reddit_nvda_sentiment import run_reddit_sentiment\n",
    "\n",
    "OUTPUT_CSV = PROJECT_ROOT / 'data' / 'interim' / 'activitiy recognition' / 'nvda_sentiment.csv'\n",
    "\n",
    "START = datetime(2024, 6, 1)\n",
    "END = datetime(2025, 7, 22)\n",
    "\n",
    "result_df = run_reddit_sentiment(\n",
    "    subreddit_name='wallstreetbets',\n",
    "    start_date=START,\n",
    "    end_date=END,\n",
    "    max_posts=2000,\n",
    "    output_csv=str(OUTPUT_CSV),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
