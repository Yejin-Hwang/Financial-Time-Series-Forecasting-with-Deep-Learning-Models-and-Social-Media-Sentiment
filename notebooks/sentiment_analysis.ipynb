{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Sentiment analysis Model Accuracy with FinancialPhrase Bank DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "# NLTK Vader download (only one time)\n",
    "# try:\n",
    "#     nltk.data.find('sentiment/vader.zip')\n",
    "# except nltk.downloader.DownloadError:\n",
    "#     nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sentiment Analysis Model Accuracy Evaluation ---\n",
      "\n",
      "--- VADER Model Evaluation (Sentences_AllAgree.txt) ---\n",
      "VADER Accuracy (100% Agree): 0.5707\n",
      "\n",
      "--- FinBERT Model Evaluation (Sentences_AllAgree.txt) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinBERT Accuracy (100% Agree): 0.9717\n",
      "\n",
      "--- DistilBERT Model Evaluation (Sentences_AllAgree.txt) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT Accuracy (100% Agree) - Note: This is a binary classification model, so there might be issues with handling 'neutral' labels: 0.2584\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess sentence, sentiment label from text file.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding='latin-1') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                # split sentence and sentiment by '@'\n",
    "                parts = line.rsplit('@', 1)\n",
    "                if len(parts) == 2:\n",
    "                    sentence = parts[0].strip()\n",
    "                    sentiment = parts[1].strip().lower()\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(sentiment)\n",
    "    return sentences, labels\n",
    "\n",
    "def convert_vader_to_sentiment(compound_score):\n",
    "    \"\"\"\n",
    "    Convert VADER compound score to 'positive', 'negative', or 'neutral'.\n",
    "    \"\"\"\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "def evaluate_vader(sentences, true_labels):\n",
    "    \"\"\"\n",
    "    Evaluates the accuracy of the VADER model.\n",
    "    \"\"\"\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    predicted_labels = []\n",
    "    for sentence in sentences:\n",
    "        scores = sid.polarity_scores(sentence)\n",
    "        predicted_labels.append(convert_vader_to_sentiment(scores['compound']))\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_bert_model(model_name, sentences, true_labels):\n",
    "    \"\"\"\n",
    "    Evaluates the accuracy of BERT-based models (FinBERT, DistilBERT).\n",
    "    \"\"\"\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    results = sentiment_pipeline(sentences)\n",
    "\n",
    "    predicted_labels = []\n",
    "    for res in results:\n",
    "        label = res['label'].lower()\n",
    "        predicted_labels.append(label)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    return accuracy\n",
    "\n",
    "base_path = \"/Users/hwang-yejin/Desktop/Summer1/Proposal/coding/FinancialPhraseBank-v1.0/\" \n",
    "\n",
    "# load data \n",
    "try:\n",
    "    sentences_50agree, labels_50agree = load_and_preprocess_data(base_path + 'Sentences_50Agree.txt')\n",
    "    sentences_66agree, labels_66agree = load_and_preprocess_data(base_path + 'Sentences_66Agree.txt')\n",
    "    sentences_75agree, labels_75agree = load_and_preprocess_data(base_path + 'Sentences_75Agree.txt')\n",
    "    sentences_allagree, labels_allagree = load_and_preprocess_data(base_path + 'Sentences_AllAgree.txt')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: file cannot be found - {e}. check the file path\")\n",
    "    exit()\n",
    "\n",
    "print(\"--- Sentiment Analysis Model Accuracy Evaluation ---\")\n",
    "\n",
    "# VADER evaluation\n",
    "print(\"\\n--- VADER Model Evaluation (Sentences_AllAgree.txt) ---\")\n",
    "vader_accuracy_allagree = evaluate_vader(sentences_allagree, labels_allagree)\n",
    "print(f\"VADER Accuracy (100% Agree): {vader_accuracy_allagree:.4f}\")\n",
    "\n",
    "# FinBERT evaluation\n",
    "print(\"\\n--- FinBERT Model Evaluation (Sentences_AllAgree.txt) ---\")\n",
    "try:\n",
    "    finbert_accuracy_allagree = evaluate_bert_model(\"ProsusAI/finbert\", sentences_allagree, labels_allagree)\n",
    "    print(f\"FinBERT Accuracy (100% Agree): {finbert_accuracy_allagree:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during FinBERT evaluation: {e}\")\n",
    "\n",
    "# DistilBERT evaluation\n",
    "print(\"\\n--- DistilBERT Model Evaluation (Sentences_AllAgree.txt) ---\")\n",
    "try:\n",
    "    distilbert_accuracy_allagree = evaluate_bert_model(\"distilbert-base-uncased-finetuned-sst-2-english\", sentences_allagree, labels_allagree)\n",
    "    print(f\"DistilBERT Accuracy (100% Agree) - Note: This is a binary classification model, so there might be issues with handling 'neutral' labels: {distilbert_accuracy_allagree:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during DistilBERT evaluation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating with Additional Datasets (Optional) ---\n",
      "\n",
      "--- VADER Model Evaluation (Sentences_75Agree.txt) ---\n",
      "VADER Accuracy (75% Agree): 0.5627\n",
      "\n",
      "--- FinBERT Model Evaluation (Sentences_75Agree.txt) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinBERT Accuracy (75% Agree): 0.9473\n",
      "\n",
      "--- DistilBERT Model Evaluation (Sentences_75Agree.txt) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT Accuracy (75% Agree) - Note: This is a binary classification model, so there might be issues with handling 'neutral' labels: 0.2667\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluating with Additional Datasets (Optional) ---\")\n",
    "\n",
    "# VADER Evaluation (75% Agree)\n",
    "print(\"\\n--- VADER Model Evaluation (Sentences_75Agree.txt) ---\")\n",
    "vader_accuracy_75agree = evaluate_vader(sentences_75agree, labels_75agree)\n",
    "print(f\"VADER Accuracy (75% Agree): {vader_accuracy_75agree:.4f}\")\n",
    "\n",
    "# FinBERT Evaluation (75% Agree)\n",
    "print(\"\\n--- FinBERT Model Evaluation (Sentences_75Agree.txt) ---\")\n",
    "try:\n",
    "    finbert_accuracy_75agree = evaluate_bert_model(\"ProsusAI/finbert\", sentences_75agree, labels_75agree)\n",
    "    print(f\"FinBERT Accuracy (75% Agree): {finbert_accuracy_75agree:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during FinBERT evaluation: {e}\")\n",
    "\n",
    "# DistilBERT Evaluation (75% Agree)\n",
    "print(\"\\n--- DistilBERT Model Evaluation (Sentences_75Agree.txt) ---\")\n",
    "try:\n",
    "    distilbert_accuracy_75agree = evaluate_bert_model(\"distilbert-base-uncased-finetuned-sst-2-english\", sentences_75agree, labels_75agree)\n",
    "    print(f\"DistilBERT Accuracy (75% Agree) - Note: This is a binary classification model, so there might be issues with handling 'neutral' labels: {distilbert_accuracy_75agree:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during DistilBERT evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with one sentence(previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /Users/hwang-\n",
      "[nltk_data]     yejin/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face (distilBERT): {'label': 'POSITIVE', 'score': 0.9973575472831726}\n",
      "FinBERT: {'negative': 0.056402043, 'neutral': 0.04639243, 'positive': 0.89720553}\n"
     ]
    }
   ],
   "source": [
    "text = \"TSLA is going to explode next week. I'm all in.\"\n",
    "\n",
    "# ① VADER/NLTK (Lexicon based)\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "print(\"VADER:\", vader.polarity_scores(text))\n",
    "\n",
    "# ② Hugging Face distilBERT (Deep Learning, General domain)\n",
    "hf = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", framework=\"pt\")\n",
    "print(\"Hugging Face (distilBERT):\", hf(text)[0])\n",
    "\n",
    "# ③ FinBERT (Deep Learning, Fiance domain-specialized)\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "inputs = finbert_tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = finbert_model(**inputs)\n",
    "probs = softmax(outputs.logits.detach().numpy()[0])\n",
    "labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "print(\"FinBERT:\", dict(zip(labels, probs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label\n",
      "0  According to Gran , the company has no plans t...   neutral\n",
      "1  For the last quarter of 2010 , Componenta 's n...  positive\n",
      "2  In the third quarter of 2010 , net sales incre...  positive\n",
      "3  Operating profit rose to EUR 13.1 mn from EUR ...  positive\n",
      "4  Operating profit totalled EUR 21.1 mn , up fro...  positive\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# file_path = \"/Users/hwang-yejin/Desktop/Summer1/Proposal/coding/FinancialPhraseBank-v1.0/Sentences_AllAgree.txt\"\n",
    "\n",
    "# with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "#     lines = f.readlines()\n",
    "\n",
    "# data = []\n",
    "# for line in lines:\n",
    "#     if \"@\" in line:\n",
    "#         sentence, label = line.strip().rsplit(\"@\", 1)\n",
    "#         data.append({\"text\": sentence.strip(), \"label\": label.strip().lower()})\n",
    "# df = pd.DataFrame(data)\n",
    "# print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
